# Results for PML assignment
-----
# rpart:
> set.seed(7)
> modelRpart <- train(classe ~ ., data=training, method="rpart",trControl=control,preProc=PP,tuneLength=15)
> predRpart <- predict(modelRpart,newdata=testing)
> mtxRpart <- confusionMatrix(predRpart,testing$classe)
> mtxRpart
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1268   82    5   19    4
         B   42  713   48   67   45
         C    0   45  704   27    2
         D   71   38   88  640   50
         E   14   71   10   51  800

Overall Statistics
                                          
               Accuracy : 0.8412          
                 95% CI : (0.8306, 0.8513)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.7992          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9090   0.7513   0.8234   0.7960   0.8879
Specificity            0.9687   0.9489   0.9817   0.9398   0.9635
Pos Pred Value         0.9202   0.7792   0.9049   0.7215   0.8457
Neg Pred Value         0.9640   0.9408   0.9634   0.9592   0.9745
Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837
Detection Rate         0.2586   0.1454   0.1436   0.1305   0.1631
Detection Prevalence   0.2810   0.1866   0.1586   0.1809   0.1929
Balanced Accuracy      0.9388   0.8501   0.9026   0.8679   0.9257

-----
# lda:
> set.seed(7)
> modelLda <- train(classe ~ ., data = training, method = "lda", trControl=control, preProc=PP, tuneLength=15)
> predLda <- predict(modelLda,newdata=testing)
> mtxLda <- confusionMatrix(predLda,testing$classe)
> mtxLda
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1161  120   84   38   38
         B   40  627   84   32  140
         C   80  133  568   91   67
         D  112   40  100  621   95
         E    2   29   19   22  561

Overall Statistics
                                         
               Accuracy : 0.7215         
                 95% CI : (0.7087, 0.734)
    No Information Rate : 0.2845         
    P-Value [Acc > NIR] : < 2.2e-16      
                                         
                  Kappa : 0.6476         
 Mcnemar's Test P-Value : < 2.2e-16      

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.8323   0.6607   0.6643   0.7724   0.6226
Specificity            0.9202   0.9252   0.9084   0.9154   0.9820
Pos Pred Value         0.8057   0.6793   0.6049   0.6415   0.8863
Neg Pred Value         0.9324   0.9191   0.9276   0.9535   0.9204
Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837
Detection Rate         0.2367   0.1279   0.1158   0.1266   0.1144
Detection Prevalence   0.2938   0.1882   0.1915   0.1974   0.1291
Balanced Accuracy      0.8762   0.7929   0.7863   0.8439   0.8023

-----
pls: 
> set.seed(7)
> modelPls <- train(classe ~ ., data = training, method = "pls", trControl=control, preProc=PP, tuneLength=15)
> predPls <- predict(modelPls,newdata=testing)
> mtxPls <- confusionMatrix(predPls,testing$classe)
> mtxPls
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1148  273  175   66   63
         B   57  418   46   60  154
         C   64  139  476   96  106
         D  107   65  130  521  103
         E   19   54   28   61  475

Overall Statistics
                                          
               Accuracy : 0.6195          
                 95% CI : (0.6057, 0.6331)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.5152          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.8229  0.44046  0.55673   0.6480  0.52719
Specificity            0.8356  0.91985  0.89998   0.9012  0.95953
Pos Pred Value         0.6655  0.56871  0.54030   0.5626  0.74568
Neg Pred Value         0.9223  0.87263  0.90579   0.9289  0.90016
Prevalence             0.2845  0.19352  0.17435   0.1639  0.18373
Detection Rate         0.2341  0.08524  0.09706   0.1062  0.09686
Detection Prevalence   0.3518  0.14988  0.17965   0.1888  0.12989
Balanced Accuracy      0.8293  0.68016  0.72835   0.7746  0.74336

-----
nb:
> set.seed(7)
> modelNb <- train(classe ~ ., data = training, method = "nb", trControl=control, preProc=PP, tuneLength=15)
> predNb <- predict(modelNb,newdata=testing)
There were 50 or more warnings (use warnings() to see the first 50)
> mtxNb <- confusionMatrix(predNb,testing$classe)
> mtxNb
Confusion Matrix and Statistics

          Reference
Prediction    A    B    C    D    E
         A 1256  184  146  118   43
         B   36  623   55    2  110
         C   23   87  597  110   28
         D   80   47   57  535   30
         E    0    8    0   39  690

Overall Statistics
                                          
               Accuracy : 0.7547          
                 95% CI : (0.7424, 0.7667)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.6869          
 Mcnemar's Test P-Value : < 2.2e-16       

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9004   0.6565   0.6982   0.6654   0.7658
Specificity            0.8601   0.9487   0.9388   0.9478   0.9883
Pos Pred Value         0.7189   0.7542   0.7065   0.7143   0.9362
Neg Pred Value         0.9560   0.9201   0.9364   0.9353   0.9494
Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837
Detection Rate         0.2561   0.1270   0.1217   0.1091   0.1407
Detection Prevalence   0.3562   0.1684   0.1723   0.1527   0.1503
Balanced Accuracy      0.8802   0.8026   0.8185   0.8066   0.8770

-----
> 
> #collect resamples
> results <- resamples(list(RPART=modelRpart, LDA=modelLda, PLS=modelPls, NB=modelNb))
> # prsent resamples information
> summary(results)

Call:
summary.resamples(object = results)

Models: RPART, LDA, PLS, NB 
Number of resamples: 30 

Accuracy 
        Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
RPART 0.7303  0.7968 0.8183 0.8137  0.8373 0.8492    0
LDA   0.6866  0.6988 0.7102 0.7089  0.7180 0.7289    0
PLS   0.5920  0.6112 0.6167 0.6150  0.6204 0.6315    0
NB    0.7342  0.7478 0.7541 0.7543  0.7596 0.7772    0

Kappa 
        Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
RPART 0.6586  0.7433 0.7698 0.7643  0.7946 0.8090    0
LDA   0.6036  0.6191 0.6331 0.6316  0.6435 0.6569    0
PLS   0.4789  0.5039 0.5106 0.5086  0.5151 0.5302    0
NB    0.6601  0.6775 0.6864 0.6867  0.6930 0.7159    0

> bwplot(results)
> dotplot(results)
> 
> # do paired t-test
> diffs <- diff(results)
> summary(diffs)

Call:
summary.diff.resamples(object = diffs)

p-value adjustment: bonferroni 
Upper diagonal: estimates of the difference
Lower diagonal: p-value for H0: difference = 0

Accuracy 
      RPART     LDA       PLS       NB      
RPART            0.10479   0.19869   0.05931
LDA   < 2.2e-16            0.09390  -0.04548
PLS   < 2.2e-16 < 2.2e-16           -0.13938
NB    3.313e-11 < 2.2e-16 < 2.2e-16         

Kappa 
      RPART     LDA       PLS       NB      
RPART            0.13270   0.25563   0.07761
LDA   < 2.2e-16            0.12293  -0.05509
PLS   < 2.2e-16 < 2.2e-16           -0.17802
NB    1.485e-11 3.555e-16 < 2.2e-16 



